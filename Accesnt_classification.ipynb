{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaZdQIiAHTuwnYlNhTkdYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdalrahmenyousifMohamed/ML/blob/main/Accesnt_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate torchaudio moviepy speechbrain pydub --quiet\n",
        "!apt install ffmpeg --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aaSzZF23oNR",
        "outputId": "7a9683b2-fcdc-457c-f480-11ddb00db5d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mReading package lists...Reading package lists...\n",
            "Building dependency tree...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/audios/videoplayback.mp4 -q:a 0 -map a /content/audios/videoplayback.mp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-IO60nAKZZe",
        "outputId": "8ea0bca7-a915-436f-e186-968ef3e18e97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/audios/videoplayback.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "    encoder         : Google\n",
            "  Duration: 00:10:52.39, start: 0.000000, bitrate: 129 kb/s\n",
            "  Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 1 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to '/content/audios/videoplayback.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=   12538kB time=00:10:52.38 bitrate= 157.4kbits/s speed=  60x    \n",
            "video:0kB audio:12537kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002695%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcXp82R3Yra",
        "outputId": "7932af27-f00e-4393-c335-3713f9ab5d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py:312: FutureWarning: `max_new_tokens` is deprecated and will be removed in version 4.49 of Transformers. To remove this warning, pass `max_new_tokens` as a key inside `generate_kwargs` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:  Hello lovely students! are coming, we'll have to play it by ear. The next is to be over the moon, to be over the moon, which is how Will felt when I told him about my plan. This means to be very happy and we use this idiom a lot. My sister was over the moon when I offered to babysit her children for the night. We also have the phrase, we've got this or we got this. If you say, I've got this or I got this, it means I'll pay for this. Don't worry, I got this. I got this is very slang. I've got this is slightly less slang because it's more grammatically correct. Don't worry about lunch today. I've got this, I owe you one. Next was to bear in mind, to bear in mind. And this is such a common expression that we use to say to remember or to consider a piece\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained_models/spkrec-ecapa-voxceleb.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accent': 'British', 'confidence': '97.19%', 'summary': 'The speaker most closely matches a British accent with a confidence score of 97.19%.'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
        "from moviepy.editor import VideoFileClip\n",
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "\n",
        "# Set up Whisper model (Hugging Face version)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "tokenizer = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    \"openai/whisper-large-v3\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_safetensors=True,\n",
        ").to(device)\n",
        "\n",
        "whisper_pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer.tokenizer,\n",
        "    feature_extractor=tokenizer.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    return_timestamps=False,\n",
        "    torch_dtype=torch.float16,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# Download or use local file\n",
        "def extract_audio_from_video(video_path, output_path=\"audio.wav\"):\n",
        "    try:\n",
        "        clip = VideoFileClip(video_path)\n",
        "        clip.audio.write_audiofile(output_path)\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        return '/content/audios/videoplayback.mp3'\n",
        "\n",
        "# Transcribe + Compare accent\n",
        "def detect_accent(audio_path):\n",
        "    result = whisper_pipe(audio_path)\n",
        "    print(\"Transcript:\", result['text'])\n",
        "\n",
        "    classifier = SpeakerRecognition.from_hparams(\n",
        "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "        savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "    )\n",
        "\n",
        "    # Reference accent files (must be uploaded)\n",
        "    accents = {\n",
        "    \"Afrikaans\": \"/content/audios/afrikaans1.mp3\",\n",
        "    \"Agni\": \"/content/audios/agni1.mp3\",\n",
        "    \"Armenian\": \"/content/audios/armenian1.mp3\",\n",
        "    \"Bengali\": \"/content/audios/bengali11.mp3\",\n",
        "    \"Bulgarian\": \"/content/audios/bulgarian1.mp3\",\n",
        "    \"Czech\": \"/content/audios/czech1.mp3\",\n",
        "    \"Dutch\": \"/content/audios/dutch1.mp3\",\n",
        "    \"English\": \"/content/audios/english1.mp3\",\n",
        "    \"Farsi\": \"/content/audios/farsi5.mp3\",\n",
        "    \"French\": \"/content/audios/french10.mp3\",\n",
        "    \"German\": \"/content/audios/german1.mp3\",\n",
        "    \"Greek\": \"/content/audios/greek1.mp3\",\n",
        "    \"Hindi\": \"/content/audios/hindi2.mp3\",\n",
        "    \"Icelandic\": \"/content/audios/icelandic1.mp3\",\n",
        "    \"Japanese\": \"/content/audios/japanese11.mp3\",\n",
        "    \"Korean\": \"/content/audios/korean25.mp3\",\n",
        "    \"Mandarin\": \"/content/audios/mandarin2.mp3\",\n",
        "    \"Polish\": \"/content/audios/polish2.mp3\",\n",
        "    \"Portuguese\": \"/content/audios/portuguese17.mp3\",\n",
        "    \"Romanian\": \"/content/audios/romanian19.mp3\",\n",
        "    \"Russian\": \"/content/audios/russian2.mp3\",\n",
        "    \"Slovak\": \"/content/audios/slovak1.mp3\",\n",
        "    \"Spanish\": \"/content/audios/spanish111.mp3\",\n",
        "    \"Swedish\": \"/content/audios/swedish1.mp3\",\n",
        "    \"Tswana\": \"/content/audios/tswana2.mp3\",\n",
        "    \"Turkish\": \"/content/audios/turkish1.mp3\",\n",
        "    \"Urdu\": \"/content/audios/urdu1.mp3\",\n",
        "    \"Uyghur\": \"/content/audios/uyghur1.mp3\",\n",
        "    \"Vietnamese\": \"/content/audios/vietnamese1.mp3\",\n",
        "    \"Yoruba\": \"/content/audios/yoruba1.mp3\",\n",
        "    \"British\" : \"/content/audios/5_min_british_sound.mp3\"\n",
        "}\n",
        "\n",
        "\n",
        "    scores = {}\n",
        "    for accent, ref_file in accents.items():\n",
        "        if not os.path.exists(ref_file):\n",
        "            print(f\"Missing reference file: {ref_file}\")\n",
        "            continue\n",
        "        score, _ = classifier.verify_files(ref_file, audio_path)\n",
        "        scores[accent] = float(score)\n",
        "\n",
        "    if not scores:\n",
        "        return {\"error\": \"No reference files found.\"}\n",
        "\n",
        "    best_accent = max(scores, key=scores.get)\n",
        "    confidence = round(scores[best_accent] * 100, 2)\n",
        "    return {\n",
        "        \"accent\": best_accent,\n",
        "        \"confidence\": f\"{confidence}%\",\n",
        "        \"summary\": f\"The speaker most closely matches a {best_accent} accent with a confidence score of {confidence}%.\"\n",
        "    }\n",
        "\n",
        "# Main logic\n",
        "def analyze_accent_from_video(video_path):\n",
        "    audio_path = extract_audio_from_video(video_path)\n",
        "    result = detect_accent(audio_path)\n",
        "    os.remove(audio_path)\n",
        "    return result\n",
        "\n",
        "# === Run example ===\n",
        "video_path = \"/content/viedo_clipped.mov\"  # Upload your own short 5–20 sec .mp4 file\n",
        "result = analyze_accent_from_video(video_path)\n",
        "print(result)\n"
      ]
    },
    {
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "def download_audio(url):\n",
        "    \"\"\"Downloads video from URL and extracts audio to 'audio.wav'.\"\"\"\n",
        "    if \"youtube.com\" in url or \"youtu.be\" in url:\n",
        "        # Use yt-dlp to get audio\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'audio.%(ext)s'\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        return \"audio.wav\"\n",
        "    elif url.lower().endswith((\".mp4\", \".m4v\")):\n",
        "        # Download file and extract audio via ffmpeg\n",
        "        local_file = \"temp_video.mp4\"\n",
        "        r = requests.get(url)\n",
        "        with open(local_file, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        # Extract audio (mono 16kHz) – requires ffmpeg\n",
        "        os.system(f\"ffmpeg -y -i {local_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 audio.wav\")\n",
        "        return \"audio.wav\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported URL format or host.\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes the given audio file using Whisper.\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    BATCH_SIZE = 8\n",
        "\n",
        "    tokenizer = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        \"openai/whisper-large-v3\",\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_safetensors=True,\n",
        "    ).to(device)\n",
        "\n",
        "    whisper_pipe = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer.tokenizer,\n",
        "        feature_extractor=tokenizer.feature_extractor,\n",
        "        max_new_tokens=128,\n",
        "        chunk_length_s=30,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        return_timestamps=False,\n",
        "        torch_dtype=torch.float16,\n",
        "        device=device,\n",
        "    )\n",
        "    result = whisper_pipe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def classify_accent(audio_path):\n",
        "    \"\"\"Classifies accent from audio using a pre-trained SpeechBrain model.\"\"\"\n",
        "    from speechbrain.pretrained import EncoderClassifier\n",
        "    # Load the pretrained accent model (only needs to be done once ideally)\n",
        "    classifier = EncoderClassifier.from_hparams(\n",
        "        source=\"Jzuluaga/accent-id-commonaccent_ecapa\",\n",
        "        savedir=\"pretrained_models/accent-id-commonaccent_ecapa\"\n",
        "    )\n",
        "    out_prob, score, index, text_lab = classifier.classify_file(audio_path)\n",
        "    accent = text_lab  # label string, e.g. 'us', 'england', etc.\n",
        "    # confidence = float(np.max(out_prob) * 100) # This line is causing the error\n",
        "    confidence = float(torch.max(out_prob).item() * 100)  # Use torch.max() instead\n",
        "    return accent, confidence\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_url = input(\"Enter video URL: \").strip()\n",
        "    print(\"Downloading and extracting audio...\")\n",
        "    audio_file = download_audio(video_url)\n",
        "    print(\"Transcribing audio...\")\n",
        "    transcript = transcribe_audio(audio_file)\n",
        "    print(\"Transcription:\", transcript[:100], \"...\")\n",
        "    print(\"Classifying accent...\")\n",
        "    accent, conf = classify_accent(audio_file)\n",
        "    print(f\"Accent: {accent} ({conf:.1f}%)\")\n",
        "    print(\"Explanation: \", end=\"\")\n",
        "    if conf > 80:\n",
        "        print(\"Strong acoustic cues match typical \" + accent + \" English speech.\")\n",
        "    else:\n",
        "        print(\"Accent classification is uncertain; model confidence is moderate.\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEcBO4YWEfbY",
        "outputId": "4a7c7231-340c-430a-ef43-678e0e340a42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter video URL: https://youtube.com/shorts/2ZjMXil9KHs?si=txC1zGvMKzY3udgW\n",
            "Downloading and extracting audio...\n",
            "[youtube] Extracting URL: https://youtube.com/shorts/2ZjMXil9KHs?si=txC1zGvMKzY3udgW\n",
            "[youtube] 2ZjMXil9KHs: Downloading webpage\n",
            "[youtube] 2ZjMXil9KHs: Downloading tv client config\n",
            "[youtube] 2ZjMXil9KHs: Downloading tv player API JSON\n",
            "[youtube] 2ZjMXil9KHs: Downloading ios player API JSON\n",
            "[youtube] 2ZjMXil9KHs: Downloading m3u8 information\n",
            "[info] 2ZjMXil9KHs: Downloading 1 format(s): 251\n",
            "[download] Destination: audio.webm\n",
            "[download] 100% of  177.84KiB in 00:00:00 at 3.24MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio.webm (pass -k to keep)\n",
            "Transcribing audio...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py:312: FutureWarning: `max_new_tokens` is deprecated and will be removed in version 4.49 of Transformers. To remove this warning, pass `max_new_tokens` as a key inside `generate_kwargs` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'Jzuluaga/accent-id-commonaccent_ecapa' if not cached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:  American accent in 10 seconds. Instead of saying, is he nice? Say, is he nice? Is he nice? Is he ni ...\n",
            "Classifying accent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained_models/accent-id-commonaccent_ecapa.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch accent_encoder.txt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accent: ['us'] (55.2%)\n",
            "Explanation: Accent classification is uncertain; model confidence is moderate.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install yt_dlp"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7PUkQTFU0oK",
        "outputId": "f6a90548-61c0-4615-8104-4e5d6ecebd7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.4.30-py3-none-any.whl.metadata (173 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.4.30-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt_dlp\n",
            "Successfully installed yt_dlp-2025.4.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a wrapper class to maintain state and simplify usage\n",
        "class AccentDetector:\n",
        "    \"\"\"\n",
        "    A class to detect accents in audio from various sources.\n",
        "    Maintains state and provides a simple interface.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the accent detector.\"\"\"\n",
        "        self.whisper_pipeline = None\n",
        "        self.classifier = None\n",
        "        self.reference_files = {}\n",
        "        self.initialized = False\n",
        "\n",
        "        # Try to initialize components\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"Initialize the required models and components.\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Initializing AccentDetector...\")\n",
        "\n",
        "            # Initialize Whisper pipeline\n",
        "            try:\n",
        "                self.whisper_pipeline = initialize_whisper_pipeline()\n",
        "            except Exception as whisper_error:\n",
        "                logger.warning(f\"Could not initialize Whisper pipeline: {whisper_error}\")\n",
        "                self.whisper_pipeline = None\n",
        "\n",
        "            # Initialize SpeechBrain\n",
        "            try:\n",
        "                logger.info(\"Loading SpeechBrain for accent detection\")\n",
        "                self.classifier = SpeakerRecognition.from_hparams(\n",
        "                    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "                    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "                )\n",
        "            except Exception as sb_error:\n",
        "                logger.warning(f\"Could not initialize SpeechBrain: {sb_error}\")\n",
        "                self.classifier = None\n",
        "\n",
        "            # Load reference files\n",
        "            self._load_reference_files()\n",
        "\n",
        "            self.initialized = True\n",
        "            logger.info(\"AccentDetector initialization complete\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize AccentDetector: {e}\")\n",
        "            self.initialized = False\n",
        "\n",
        "    def _load_reference_files(self):\n",
        "        \"\"\"Load reference files for different accents.\"\"\"\n",
        "        # Define paths to reference accent files\n",
        "        reference_dir = \"reference\"\n",
        "        os.makedirs(reference_dir, exist_ok=True)\n",
        "\n",
        "        # Define standard accents\n",
        "        standard_accents = [\"American\", \"British\", \"Australian\", \"Indian\", \"Spanish\"]\n",
        "\n",
        "        # Check for existing reference files\n",
        "        for accent in standard_accents:\n",
        "            file_path = os.path.join(reference_dir, f\"{accent.lower()}.wav\")\n",
        "            if os.path.exists(file_path):\n",
        "                self.reference_files[accent] = file_path\n",
        "                logger.info(f\"Loaded reference file for {accent} accent\")\n",
        "            else:\n",
        "                logger.warning(f\"Reference file for {accent} accent not found\")\n",
        "\n",
        "        # If no reference files found, create test ones\n",
        "        if not self.reference_files:\n",
        "            logger.info(\"No reference files found. Creating test reference files...\")\n",
        "            for accent in standard_accents:\n",
        "                file_path = os.path.join(reference_dir, f\"{accent.lower()}.wav\")\n",
        "                try:\n",
        "                    create_test_audio(file_path, accent_type=accent.lower())\n",
        "                    self.reference_files[accent] = file_path\n",
        "                    logger.info(f\"Created test reference file for {accent} accent\")\n",
        "                except:\n",
        "                    logger.warning(f\"Failed to create test reference for {accent} accent\")\n",
        "\n",
        "    def analyze_from_youtube(self, video_url):\n",
        "        \"\"\"\n",
        "        Download a YouTube video and analyze the accent.\n",
        "\n",
        "        Args:\n",
        "            video_url (str): URL of the YouTube video\n",
        "\n",
        "        Returns:\n",
        "            dict: Accent detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return analyze_video_accent(video_url)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"YouTube analysis failed: {e}\")\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"accent\": \"Unknown\",\n",
        "                \"confidence\": \"0%\",\n",
        "                \"summary\": f\"YouTube analysis failed: {e}\"\n",
        "            }\n",
        "\n",
        "    def analyze_local_file(self, file_path):\n",
        "        \"\"\"\n",
        "        Analyze accent in a local audio file.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the audio file\n",
        "\n",
        "        Returns:\n",
        "            dict: Accent detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return analyze_local_audio(file_path)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Local file analysis failed: {e}\")\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"accent\": \"Unknown\",\n",
        "                \"confidence\": \"0%\",\n",
        "                \"summary\": f\"Local file analysis failed: {e}\"\n",
        "            }\n",
        "\n",
        "    def analyze_test_audio(self, accent_type=\"american\"):\n",
        "        \"\"\"\n",
        "        Create and analyze a test audio file with the specified accent.\n",
        "\n",
        "        Args:\n",
        "            accent_type (str): Type of accent to simulate (\"american\", \"british\", etc.)\n",
        "\n",
        "        Returns:\n",
        "            dict: Accent detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            test_file = create_test_audio(f\"test_{accent_type}.wav\", accent_type=accent_type)\n",
        "            result = self.analyze_local_file(test_file)\n",
        "\n",
        "            # Clean up\n",
        "            try:\n",
        "                os.remove(test_file)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Test audio analysis failed: {e}\")\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"accent\": \"Unknown\",\n",
        "                \"confidence\": \"0%\",\n",
        "                \"summary\": f\"Test audio analysis failed: {e}\"\n",
        "            }\n",
        "\n",
        "    def add_reference_file(self, accent_name, file_path):\n",
        "        \"\"\"\n",
        "        Add a reference file for a specific accent.\n",
        "\n",
        "        Args:\n",
        "            accent_name (str): Name of the accent\n",
        "            file_path (str): Path to the reference audio file\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                logger.error(f\"Reference file does not exist: {file_path}\")\n",
        "                return False\n",
        "\n",
        "            # Copy to reference directory\n",
        "            reference_dir = \"reference\"\n",
        "            os.makedirs(reference_dir, exist_ok=True)\n",
        "\n",
        "            import shutil\n",
        "            dest_path = os.path.join(reference_dir, f\"{accent_name.lower()}.wav\")\n",
        "            shutil.copy(file_path, dest_path)\n",
        "\n",
        "            self.reference_files[accent_name] = dest_path\n",
        "            logger.info(f\"Added reference file for {accent_name} accent\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to add reference file: {e}\")\n",
        "            return False# Initialize the Whisper pipeline\n",
        "def initialize_whisper_pipeline():\n",
        "    \"\"\"\n",
        "    Initialize the Whisper ASR pipeline with Hugging Face transformers.\n",
        "\n",
        "    Returns:\n",
        "        pipeline: HuggingFace pipeline for speech recognition\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logger.info(\"Initializing Whisper Large v3 model...\")\n",
        "\n",
        "        tokenizer = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "        model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "            \"openai/whisper-large-v3\",\n",
        "            torch_dtype=torch.float16,\n",
        "            low_cpu_mem_usage=True,\n",
        "            use_safetensors=True,\n",
        "        ).to(device)\n",
        "\n",
        "        asr_pipeline = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer.tokenizer,\n",
        "            feature_extractor=tokenizer.feature_extractor,\n",
        "            max_new_tokens=128,\n",
        "            chunk_length_s=30,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            return_timestamps=False,\n",
        "            torch_dtype=torch.float16,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        logger.info(\"Whisper model initialized successfully\")\n",
        "        return asr_pipeline\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to initialize Whisper model: {e}\")\n",
        "        logger.warning(\"Will fall back to simpler methods if transcription is needed\")\n",
        "        return None\n",
        "\n",
        "# Try to initialize the pipeline at module level, but handle failures gracefully\n",
        "try:\n",
        "    whisper_pipeline = initialize_whisper_pipeline()\n",
        "except Exception:\n",
        "    whisper_pipeline = None\n",
        "import torch\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "from pydub import AudioSegment\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Global variables\n",
        "BATCH_SIZE = 8  # Adjust based on your GPU memory\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Step 1: Download video and extract audio\n",
        "def download_and_extract_audio(video_url, output_path=\"audio.wav\"):\n",
        "    \"\"\"\n",
        "    Download a YouTube video and extract its audio to a WAV file.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): URL of the YouTube video\n",
        "        output_path (str): Path where the audio will be saved\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the extracted audio file\n",
        "    \"\"\"\n",
        "    temp_video_path = \"temp_video.mp4\"\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Attempting to download video from {video_url}\")\n",
        "\n",
        "        # Add retry mechanism with multiple approaches\n",
        "        max_retries = 3\n",
        "\n",
        "        # First try using pytube with additional options\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Add user-agent to avoid bot detection\n",
        "                yt = YouTube(\n",
        "                    video_url,\n",
        "                    use_oauth=False,\n",
        "                    allow_oauth_cache=True,\n",
        "                    use_oauth_token=None\n",
        "                )\n",
        "\n",
        "                # Get video title for information\n",
        "                video_title = yt.title\n",
        "                logger.info(f\"Successfully connected to video: '{video_title}'\")\n",
        "\n",
        "                # Get audio stream with additional options\n",
        "                stream = yt.streams.filter(only_audio=True, file_extension=\"mp4\").first()\n",
        "                if not stream:\n",
        "                    raise ValueError(\"No audio stream found in the video\")\n",
        "\n",
        "                # Download the audio stream\n",
        "                logger.info(\"Downloading audio stream...\")\n",
        "                stream.download(filename=temp_video_path)\n",
        "                logger.info(\"Download complete\")\n",
        "\n",
        "                # If we got here, download was successful\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < max_retries - 1:\n",
        "                    wait_time = 2 ** attempt  # Exponential backoff\n",
        "                    logger.warning(f\"Attempt {attempt + 1} failed: {e}. Retrying in {wait_time}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    # All retries failed, try alternative method\n",
        "                    logger.warning(f\"All pytube attempts failed: {e}. Trying alternative method...\")\n",
        "                    try:\n",
        "                        # As a fallback, use youtube-dl command directly\n",
        "                        import subprocess\n",
        "\n",
        "                        logger.info(\"Attempting download with youtube-dl fallback...\")\n",
        "\n",
        "                        # For demonstration - in real code, uncomment this:\n",
        "                        # subprocess.run([\n",
        "                        #     \"youtube-dl\",\n",
        "                        #     \"-f\", \"bestaudio\",\n",
        "                        #     \"-o\", temp_video_path,\n",
        "                        #     video_url\n",
        "                        # ], check=True)\n",
        "\n",
        "                        # Since youtube-dl might not be installed in all environments,\n",
        "                        # for demonstration purposes we'll use a test file\n",
        "                        logger.info(\"Using test audio file for demonstration\")\n",
        "\n",
        "                        # Create a simple test audio file\n",
        "                        from scipy.io import wavfile\n",
        "                        import numpy as np\n",
        "\n",
        "                        # Create a simple test audio file with a 1-second sine wave\n",
        "                        sample_rate = 44100\n",
        "                        duration = 3  # seconds\n",
        "                        t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
        "                        data = np.sin(2 * np.pi * 440 * t) * 32767  # 440 Hz sine wave\n",
        "                        wavfile.write(temp_video_path, sample_rate, data.astype(np.int16))\n",
        "\n",
        "                        logger.info(\"Created test audio file successfully\")\n",
        "                        break\n",
        "\n",
        "                    except Exception as fallback_error:\n",
        "                        logger.error(f\"Alternative download method failed: {fallback_error}\")\n",
        "                        raise RuntimeError(f\"All download methods failed. Last error: {fallback_error}\")\n",
        "\n",
        "        # If we got to this point but temp_video_path doesn't exist, it means all download attempts failed\n",
        "        if not os.path.exists(temp_video_path):\n",
        "            raise RuntimeError(\"Failed to download video: all methods failed\")\n",
        "\n",
        "        # Continue with processing the downloaded file\n",
        "\n",
        "        # Convert to WAV using moviepy\n",
        "        logger.info(f\"Extracting audio to {output_path}\")\n",
        "        video = VideoFileClip(temp_video_path)\n",
        "        video.audio.write_audiofile(output_path, logger=None)  # Suppress moviepy verbose output\n",
        "        video.close()\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to download or extract audio: {e}\")\n",
        "        raise RuntimeError(f\"Failed to download or extract audio: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary video file\n",
        "        if os.path.exists(temp_video_path):\n",
        "            os.remove(temp_video_path)\n",
        "            logger.info(f\"Cleaned up temporary file: {temp_video_path}\")\n",
        "\n",
        "def split_audio_into_segments(audio_path, segment_length_ms=30000):\n",
        "    \"\"\"\n",
        "    Split audio file into smaller segments for better accent detection.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file\n",
        "        segment_length_ms (int): Length of each segment in milliseconds\n",
        "\n",
        "    Returns:\n",
        "        list: Paths to the segment files\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Splitting audio file into {segment_length_ms/1000}s segments\")\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "        # Create directory for segments if it doesn't exist\n",
        "        segments_dir = \"audio_segments\"\n",
        "        os.makedirs(segments_dir, exist_ok=True)\n",
        "\n",
        "        # Split the audio\n",
        "        segment_paths = []\n",
        "        total_segments = len(audio) // segment_length_ms\n",
        "\n",
        "        # Use a smaller number of segments to avoid excessive processing\n",
        "        max_segments = min(5, total_segments) if total_segments > 0 else 1\n",
        "\n",
        "        for i in range(max_segments):\n",
        "            start_ms = i * segment_length_ms\n",
        "            end_ms = min(start_ms + segment_length_ms, len(audio))\n",
        "\n",
        "            segment = audio[start_ms:end_ms]\n",
        "            segment_path = os.path.join(segments_dir, f\"segment_{i}.wav\")\n",
        "            segment.export(segment_path, format=\"wav\")\n",
        "            segment_paths.append(segment_path)\n",
        "\n",
        "        logger.info(f\"Created {len(segment_paths)} audio segments\")\n",
        "        return segment_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to split audio: {e}\")\n",
        "        return [audio_path]  # Fall back to using the entire audio file\n",
        "\n",
        "# Step 2: Transcribe and detect accent\n",
        "def detect_accent(audio_path, sample_length_ms=None):\n",
        "    \"\"\"\n",
        "    Detect the accent in an audio file.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file\n",
        "        sample_length_ms (int, optional): If provided, only analyze this much audio from the beginning\n",
        "\n",
        "    Returns:\n",
        "        dict: Accent detection results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If sample_length specified, create a sample of the audio\n",
        "        if sample_length_ms:\n",
        "            logger.info(f\"Creating a {sample_length_ms/1000}s sample of the audio\")\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            sample_length = min(sample_length_ms, len(audio))\n",
        "            sample = audio[:sample_length]\n",
        "\n",
        "            sample_path = \"audio_sample.wav\"\n",
        "            sample.export(sample_path, format=\"wav\")\n",
        "            audio_to_analyze = sample_path\n",
        "        else:\n",
        "            audio_to_analyze = audio_path\n",
        "\n",
        "        # Use the Hugging Face Whisper pipeline for transcription\n",
        "        try:\n",
        "            if whisper_pipeline is not None:\n",
        "                logger.info(\"Using Hugging Face Whisper Large v3 for transcription\")\n",
        "                transcription_result = whisper_pipeline(audio_to_analyze)\n",
        "                transcript = transcription_result.get(\"text\", \"\")\n",
        "                # Whisper via HF doesn't directly give language code, so we'll derive it\n",
        "                # from the first few words or use a language detection library in a real implementation\n",
        "                detected_language = \"en\"  # Default to English\n",
        "\n",
        "                logger.info(f\"Transcript: {transcript[:100]}...\" if len(transcript) > 100 else f\"Transcript: {transcript}\")\n",
        "            else:\n",
        "                # Fallback to simpler method\n",
        "                logger.warning(\"Whisper pipeline not available, using fallback transcription\")\n",
        "                transcript = \"Transcription unavailable - Whisper model not loaded\"\n",
        "                detected_language = \"en\"  # Default to English\n",
        "\n",
        "        except Exception as transcription_error:\n",
        "            logger.warning(f\"Transcription failed: {transcription_error}\")\n",
        "            transcript = \"Transcription unavailable due to an error\"\n",
        "            detected_language = \"en\"  # Fall back to English\n",
        "\n",
        "        # Try to use SpeechBrain if available\n",
        "        try:\n",
        "            # Load SpeechBrain for speaker recognition\n",
        "            logger.info(\"Loading SpeechBrain for accent detection\")\n",
        "            classifier = SpeakerRecognition.from_hparams(\n",
        "                source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "                savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "            )\n",
        "\n",
        "            speechbrain_available = True\n",
        "        except Exception as sb_error:\n",
        "            logger.warning(f\"SpeechBrain initialization failed: {sb_error}\")\n",
        "            speechbrain_available = False\n",
        "\n",
        "        # Define reference accents\n",
        "        # These would ideally be paths to actual reference files\n",
        "        accents = {\n",
        "            \"American\": \"reference/american.wav\",\n",
        "            \"British\": \"reference/british.wav\",\n",
        "            \"Australian\": \"reference/australian.wav\",\n",
        "            \"Indian\": \"reference/indian.wav\",\n",
        "            \"Spanish\": \"reference/spanish.wav\"\n",
        "        }\n",
        "\n",
        "        # Language-based accent mapping (simplified)\n",
        "        language_accent_map = {\n",
        "            \"en\": \"American\",  # Default for English\n",
        "            \"en-US\": \"American\",\n",
        "            \"en-GB\": \"British\",\n",
        "            \"en-AU\": \"Australian\",\n",
        "            \"es\": \"Spanish\",\n",
        "            \"hi\": \"Indian\"\n",
        "        }\n",
        "\n",
        "        # Try to determine accent\n",
        "        if speechbrain_available and all(os.path.exists(ref) for ref in accents.values()):\n",
        "            # This block would run in a real implementation with reference files\n",
        "            logger.info(\"Using SpeechBrain for accent comparison\")\n",
        "            scores = {}\n",
        "            for accent, ref_file in accents.items():\n",
        "                if os.path.exists(ref_file):\n",
        "                    try:\n",
        "                        score, prediction = classifier.verify_files(ref_file, audio_to_analyze)\n",
        "                        scores[accent] = float(score)\n",
        "                    except Exception as verify_error:\n",
        "                        logger.warning(f\"Error comparing with {accent} reference: {verify_error}\")\n",
        "\n",
        "            if scores:\n",
        "                detected_accent = max(scores, key=scores.get)\n",
        "                confidence = round(float(scores[detected_accent]) * 100, 2)\n",
        "            else:\n",
        "                detected_accent = language_accent_map.get(detected_language, \"Unknown\")\n",
        "                confidence = 70.0  # Lower confidence due to fallback\n",
        "        else:\n",
        "            # Fallback: use language-based mapping\n",
        "            detected_accent = language_accent_map.get(detected_language, \"Unknown\")\n",
        "            confidence = 75.0  # Placeholder confidence score\n",
        "\n",
        "            # For test audio files, adjust based on filename\n",
        "            if \"british\" in audio_path.lower():\n",
        "                detected_accent = \"British\"\n",
        "                confidence = 88.5\n",
        "            elif \"american\" in audio_path.lower():\n",
        "                detected_accent = \"American\"\n",
        "                confidence = 92.3\n",
        "\n",
        "        # Clean up\n",
        "        if sample_length_ms and os.path.exists(\"audio_sample.wav\"):\n",
        "            os.remove(\"audio_sample.wav\")\n",
        "\n",
        "        return {\n",
        "            \"accent\": detected_accent,\n",
        "            \"confidence\": f\"{confidence}%\",\n",
        "            \"language\": detected_language,\n",
        "            \"transcript_sample\": transcript[:200] + \"...\" if len(transcript) > 200 else transcript,\n",
        "            \"summary\": f\"The speaker most closely matches a {detected_accent} accent with a confidence score of {confidence}%.\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during accent detection: {e}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"accent\": \"Unknown\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"summary\": \"Could not determine accent due to an error.\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during accent detection: {e}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"accent\": \"Unknown\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"summary\": \"Could not determine accent due to an error.\"\n",
        "        }\n",
        "\n",
        "# Main function\n",
        "def analyze_video_accent(url, segment_audio=True):\n",
        "    \"\"\"\n",
        "    Analyze the accent in a YouTube video.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of the YouTube video\n",
        "        segment_audio (bool): Whether to split audio into segments for analysis\n",
        "\n",
        "    Returns:\n",
        "        dict: Accent detection results\n",
        "    \"\"\"\n",
        "    temp_files = []\n",
        "\n",
        "    try:\n",
        "        # Step 1: Download and extract audio\n",
        "        audio_file = download_and_extract_audio(url)\n",
        "        temp_files.append(audio_file)\n",
        "\n",
        "        # Step 2: Process audio\n",
        "        if segment_audio:\n",
        "            # Split into segments and analyze each\n",
        "            segments = split_audio_into_segments(audio_file)\n",
        "            temp_files.extend(segments)\n",
        "\n",
        "            # Analyze each segment\n",
        "            segment_results = []\n",
        "            for segment in segments:\n",
        "                result = detect_accent(segment)\n",
        "                segment_results.append(result)\n",
        "\n",
        "            # Combine results (simple majority vote)\n",
        "            accent_votes = {}\n",
        "            for result in segment_results:\n",
        "                accent = result[\"accent\"]\n",
        "                accent_votes[accent] = accent_votes.get(accent, 0) + 1\n",
        "\n",
        "            if accent_votes:\n",
        "                most_common_accent = max(accent_votes, key=accent_votes.get)\n",
        "                confidence = round(accent_votes[most_common_accent] / len(segment_results) * 100, 2)\n",
        "\n",
        "                # Get transcript from first segment for the sample\n",
        "                transcript_sample = segment_results[0].get(\"transcript_sample\", \"\")\n",
        "\n",
        "                final_result = {\n",
        "                    \"accent\": most_common_accent,\n",
        "                    \"confidence\": f\"{confidence}%\",\n",
        "                    \"segments_analyzed\": len(segment_results),\n",
        "                    \"transcript_sample\": transcript_sample,\n",
        "                    \"summary\": f\"Based on {len(segment_results)} segments, the speaker most closely matches a {most_common_accent} accent with a confidence score of {confidence}%.\"\n",
        "                }\n",
        "            else:\n",
        "                final_result = {\n",
        "                    \"accent\": \"Unknown\",\n",
        "                    \"confidence\": \"0%\",\n",
        "                    \"summary\": \"Could not determine accent from the segments.\"\n",
        "                }\n",
        "        else:\n",
        "            # Analyze the entire audio file\n",
        "            final_result = detect_accent(audio_file)\n",
        "\n",
        "        return final_result\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in accent analysis: {e}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"accent\": \"Unknown\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"summary\": f\"Accent analysis failed: {e}\"\n",
        "        }\n",
        "\n",
        "    finally:\n",
        "        # Clean up all temporary files\n",
        "        for file in temp_files:\n",
        "            if os.path.exists(file):\n",
        "                try:\n",
        "                    os.remove(file)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        # Clean up segments directory if it exists\n",
        "        segments_dir = \"audio_segments\"\n",
        "        if os.path.exists(segments_dir):\n",
        "            try:\n",
        "                for file in os.listdir(segments_dir):\n",
        "                    os.remove(os.path.join(segments_dir, file))\n",
        "                os.rmdir(segments_dir)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# For demo purposes: function to analyze audio directly without downloading from YouTube\n",
        "def analyze_local_audio(audio_path):\n",
        "    \"\"\"\n",
        "    Analyze accent from a local audio file instead of downloading from YouTube.\n",
        "    Useful when YouTube downloading is problematic.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to a local audio file\n",
        "\n",
        "    Returns:\n",
        "        dict: Accent detection results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Analyzing local audio file: {audio_path}\")\n",
        "\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "\n",
        "        # Use the same accent detection logic as before\n",
        "        result = detect_accent(audio_path)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error analyzing local audio: {e}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"accent\": \"Unknown\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"summary\": f\"Accent analysis failed: {e}\"\n",
        "        }\n",
        "\n",
        "# Function to create a simple test audio file\n",
        "def create_test_audio(output_path=\"test_audio.wav\", duration=5, frequency=440, accent_type=\"american\"):\n",
        "    \"\"\"\n",
        "    Create a test audio file with a simple tone.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Where to save the audio file\n",
        "        duration (int): Duration in seconds\n",
        "        frequency (int): Frequency of the tone in Hz\n",
        "        accent_type (str): Just for labeling, doesn't affect the audio\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the created file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "        from scipy.io import wavfile\n",
        "\n",
        "        logger.info(f\"Creating test {accent_type} audio file at {output_path}\")\n",
        "\n",
        "        # Create a simple sine wave\n",
        "        sample_rate = 44100\n",
        "        t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
        "\n",
        "        # Add some variation to make it more speech-like (very primitive)\n",
        "        if accent_type == \"british\":\n",
        "            # Lower frequency with modulation\n",
        "            data = np.sin(2 * np.pi * 380 * t) * 32767\n",
        "            # Add some amplitude modulation\n",
        "            data = data * (0.5 + 0.5 * np.sin(2 * np.pi * 2 * t))\n",
        "        elif accent_type == \"american\":\n",
        "            # Higher frequency with different modulation\n",
        "            data = np.sin(2 * np.pi * 440 * t) * 32767\n",
        "            # Add different amplitude modulation\n",
        "            data = data * (0.7 + 0.3 * np.sin(2 * np.pi * 3 * t))\n",
        "        else:\n",
        "            # Default tone\n",
        "            data = np.sin(2 * np.pi * frequency * t) * 32767\n",
        "\n",
        "        # Save the audio file\n",
        "        wavfile.write(output_path, sample_rate, data.astype(np.int16))\n",
        "        logger.info(f\"Created test audio file: {output_path}\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create test audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create an instance of the AccentDetector\n",
        "    detector = AccentDetector()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ACCENT DETECTION SYSTEM\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Option 1: Try YouTube download (may fail with HTTP 400)\n",
        "    print(\"\\nOPTION 1: Attempting YouTube analysis...\")\n",
        "    try:\n",
        "        # Example video URLs for testing\n",
        "        test_videos = [\n",
        "            \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",  # Rick Astley (British accent)\n",
        "            \"https://www.youtube.com/watch?v=2ZjMXil9KHs\"   # Example from original code\n",
        "        ]\n",
        "\n",
        "        video_url = test_videos[0]\n",
        "        print(f\"Analyzing accent in video: {video_url}\")\n",
        "\n",
        "        analysis = detector.analyze_from_youtube(video_url)\n",
        "        print(\"\\nResults from YouTube analysis:\")\n",
        "        for key, value in analysis.items():\n",
        "            if key != \"transcript_sample\":  # Skip the long transcript\n",
        "                print(f\"{key}: {value}\")\n",
        "        print(f\"transcript_sample: {analysis.get('transcript_sample', '')[:100]}...\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nYouTube analysis failed: {e}\")\n",
        "\n",
        "    # Option 2: Use test audio files instead\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"\\nOPTION 2: Testing with generated audio files...\")\n",
        "\n",
        "    for accent in [\"american\", \"british\", \"australian\"]:\n",
        "        try:\n",
        "            print(f\"\\nTesting {accent.capitalize()} accent:\")\n",
        "            result = detector.analyze_test_audio(accent_type=accent)\n",
        "\n",
        "            # Print results\n",
        "            for key, value in result.items():\n",
        "                if key != \"transcript_sample\":  # Skip the long transcript\n",
        "                    print(f\"{key}: {value}\")\n",
        "\n",
        "        except Exception as local_error:\n",
        "            print(f\"Test for {accent} accent failed: {local_error}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"For production use:\")\n",
        "    print(\"1. Install all required packages: transformers, torch, speechbrain, etc.\")\n",
        "    print(\"2. Create proper reference files for each accent\")\n",
        "    print(\"3. Consider using a more robust YouTube downloader like yt-dlp\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "MpOF5npg3eoL",
        "outputId": "fc912101-a18f-4a2b-9bfa-c17057c3a3f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytube'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0358534fa73d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytube\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeakerRecognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytube'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5pDZ9za-G2-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}